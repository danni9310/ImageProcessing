{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Guide for detecting areas and text in an image</h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important things for the protocol:\n",
    "\n",
    "1. Circles in the paper have to be really separate. It will be easy split both circles.\n",
    "2. Unncessary letters and lines for the processing have to be in light color. It will help in umbralization process. \n",
    "3. It is important to use thick marks for relevant lines\n",
    "4. Stickers can't cut the lines because after it will not be possible separete this section\n",
    "5. Script works better with uppercase letters while they are aligned (we tryed with numbers and lowercase letter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src= \"sources/processing_detect_text.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./S1/Scanner/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x25d16931cc0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Open image \n",
    "participant = 'S1'\n",
    "path = './' + participant + r'/Scanner/'\n",
    "pathSave = './' + participant + r'/Areas/'\n",
    "pathLetters = './' + participant + r'/Letters/'\n",
    "pathTexts = './' + participant + r'/Texts/'\n",
    "imageName = 'A1.jpg'\n",
    "names = ['Left', 'Right', 'Up', 'Down', 'Straight']\n",
    "print(path)\n",
    "image = cv2.imread(path + imageName) \n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sections: 24\n",
      "Area  1424288\n",
      "Area  3134509\n",
      "Area  560764\n",
      "Area  200351\n",
      "Area  174386\n",
      "Images saved in folder\n"
     ]
    }
   ],
   "source": [
    "# Split images in the same page\n",
    "\n",
    "middle = int(len(image)/2) \n",
    "\n",
    "image1 = image[:middle]\n",
    "image2 = image[middle:]\n",
    "\n",
    "# Select image (image1 or image 2) for processing and binarization \n",
    "\n",
    "setImage = image2\n",
    "threshold = 170\n",
    "# 170\n",
    "grayImage = cv2.cvtColor(setImage, cv2.COLOR_BGR2GRAY)\n",
    "_, binaryImage = cv2.threshold(grayImage, threshold, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Binarization for getting numbers\n",
    "\n",
    "threshold = 40\n",
    "# 45\n",
    "_, number = cv2.threshold(grayImage, threshold, 255, cv2.THRESH_BINARY)\n",
    "kernel = np.ones((3, 3), np.uint8)\n",
    "number = cv2.dilate(~number, kernel, iterations=4)\n",
    "\n",
    "# Delete number in the image \n",
    "\n",
    "result = ~binaryImage - (number)\n",
    "plt.imshow(result)\n",
    "\n",
    "# Get exteral contour and separate main circle \n",
    "\n",
    "r,c = np.shape(grayImage)\n",
    "ext = np.zeros((r,c), np.dtype('uint8'))\n",
    "    \n",
    "contour,_ = cv2.findContours(result, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "ext = cv2.drawContours(ext, contour, -1, 255, -1)\n",
    "\n",
    "# delete small points in the image\n",
    "kernel = np.ones((2, 2), np.uint8)\n",
    "extErode= cv2.erode(ext, kernel, iterations=5)\n",
    "extDilate = cv2.dilate(extErode, kernel, iterations=5)\n",
    "\n",
    "# find where the circle is and make a cropped region\n",
    "points = np.argwhere(extDilate==255) # find where the black pixels are\n",
    "points = np.fliplr(points) # store them in x,y coordinates instead of row,col indices\n",
    "x, y, w, h = cv2.boundingRect(points) # create a rectangle around those points\n",
    "x, y, w, h = x-10, y-10, w+20, h+20 # make the box a little bigger\n",
    "\n",
    "# Cropp image\n",
    "imaIn = ~result[y:y+h, x:x+w]*ext[y:y+h, x:x+w]\n",
    "kernel = np.ones((3, 3), np.uint8)\n",
    "splitArea = cv2.dilate(~imaIn, kernel, iterations=3)\n",
    "plt.imshow(splitArea)\n",
    "\n",
    "# Identify secction and put specific lables for each one\n",
    "\n",
    "sections, labels = cv2.connectedComponents(imaIn)\n",
    "print('Number of sections: ' + str(sections-1))\n",
    "\n",
    "# Get each section, make a mask with original image and save it\n",
    "for i in range(sections):\n",
    "    area = np.sum(labels==i)\n",
    "    if (area > 200):\n",
    "        print ('Area ', str(area))\n",
    "        section =  labels.copy()\n",
    "        section[section != i] = 0\n",
    "        section[section == i] = 255\n",
    "        newSection = section.astype(np.uint8)\n",
    "        newImage = cv2.bitwise_and(setImage[y:y+h, x:x+w], setImage[y:y+h, x:x+w], mask=newSection)\n",
    "        cv2.imwrite( pathSave + names[1] + '_' + str(area) +'.png', newImage)\n",
    "\n",
    "print('Images saved in folder')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 align=\"center\">Secction for text processing - One folder with images</h3> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part is posible to detect the text in a group of image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Left_1401482.png', 'Left_3335282.png', 'Left_354293.png', 'Left_431340.png', 'Right_1424288.png', 'Right_174386.png', 'Right_200351.png', 'Right_3134509.png', 'Right_560764.png']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "files = os.listdir(pathSave)\n",
    "print (files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Left_1401482.png\n",
      "Processing: Left_3335282.png\n",
      "Processing: Left_354293.png\n",
      "Processing: Left_431340.png\n",
      "Processing: Right_1424288.png\n",
      "Processing: Right_174386.png\n",
      "Processing: Right_200351.png\n",
      "Processing: Right_3134509.png\n",
      "Processing: Right_560764.png\n"
     ]
    }
   ],
   "source": [
    "for imageName in files:\n",
    "    print ('Processing: ' + imageName)\n",
    "    \n",
    "    image = cv2.imread(pathSave + imageName) \n",
    "    threshold = 150\n",
    "    grayImage = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    _, binaryImage = cv2.threshold(grayImage, threshold, 255, cv2.THRESH_BINARY)\n",
    "    kernel = np.ones((2, 2), np.uint8)\n",
    "    splitArea = cv2.dilate(~binaryImage, kernel, iterations=1)\n",
    "    \n",
    "    r,c = np.shape(grayImage)\n",
    "    ext = np.zeros((r,c), np.dtype('uint8'))\n",
    "\n",
    "    contour,_ = cv2.findContours(~splitArea, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    ext = cv2.drawContours(ext, contour, -1, 255, -1)\n",
    "\n",
    "    imaIn = (splitArea*ext)\n",
    "\n",
    "    cv2.imwrite( pathLetters + imageName[:-4] + '.png', ~(imaIn*255))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Left_1401482.png', 'Left_3335282.png', 'Left_354293.png', 'Left_431340.png', 'Right_1424288.png', 'Right_174386.png', 'Right_200351.png', 'Right_3134509.png', 'Right_560764.png']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "files = os.listdir(pathLetters)\n",
    "print (files)\n",
    "imageName = 'Left_354293.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Direction: Left\n",
      "Area: \f",
      "Pixeles: 1401482\n",
      "\n",
      "Direction: Left\n",
      "Area: 1\"\n",
      "â€˜\n",
      ". *\n",
      ":\n",
      "\f",
      "Pixeles: 3335282\n",
      "\n",
      "Direction: Left\n",
      "Area: FA\n",
      "\f",
      "Pixeles: 354293\n",
      "\n",
      "Direction: Left\n",
      "Area: F3\n",
      "\f",
      "Pixeles: 431340\n",
      "\n",
      "Direction: Right\n",
      "Area: \f",
      "Pixeles: 1424288\n",
      "\n",
      "Direction: Right\n",
      "Area: FS\n",
      "\f",
      "Pixeles: 174386\n",
      "\n",
      "Direction: Right\n",
      "Area: F2\n",
      "\f",
      "Pixeles: 200351\n",
      "\n",
      "Direction: Right\n",
      "Area: \f",
      "Pixeles: 3134509\n",
      "\n",
      "Direction: Right\n",
      "Area: F3\n",
      "\f",
      "Pixeles: 560764\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for file in files: \n",
    "    commandLine = 'tesseract ' + pathLetters + file[:-4] + '.png' + ' ' + pathTexts + file[:-4] + ' -l eng --psm 6'\n",
    "    os.system(commandLine)\n",
    "    f = open(pathTexts + file[:-4] + '.txt', \"r\")\n",
    "    text = f.read()\n",
    "    print('Direction: ' + file[:-4].split('_')[0] + '\\n' + 'Area: ' + text + 'Pixeles: ' + file[:-4].split('_')[1] +'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Useful information for tesserat commands:\n",
    "\n",
    "tesseract --help-psm\n",
    "Page segmentation modes:\n",
    "  0    Orientation and script detection (OSD) only.\n",
    "  1    Automatic page segmentation with OSD.\n",
    "  2    Automatic page segmentation, but no OSD, or OCR.\n",
    "  3    Fully automatic page segmentation, but no OSD. (Default)\n",
    "  4    Assume a single column of text of variable sizes.\n",
    "  5    Assume a single uniform block of vertically aligned text.\n",
    "  6    Assume a single uniform block of text.\n",
    "  7    Treat the image as a single text line.\n",
    "  8    Treat the image as a single word.\n",
    "  9    Treat the image as a single word in a circle.\n",
    " 10    Treat the image as a single character.\n",
    " 11    Sparse text. Find as much text as possible in no particular order.\n",
    " 12    Sparse text with OSD.\n",
    " 13    Raw line. Treat the image as a single text line,\n",
    "       bypassing hacks that are Tesseract-specific.\n",
    " \n",
    " tesseract numero2.png outputbase -l eng --psm 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    points = np.argwhere(ext==255) # find where the black pixels are\n",
    "    points = np.fliplr(points) # store them in x,y coordinates instead of row,col indices\n",
    "    x, y, w, h = cv2.boundingRect(points) # create a rectangle around those points\n",
    "    x, y, w, h = x-10, y-10, w+20, h+20 # make the box a little bigger\n",
    "    crop = ext[y:y+h, x:x+w] # create a cropped region of the gray image\n",
    "    imaIn = (splitArea[y:y+h, x:x+w]*ext[y:y+h, x:x+w])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
