{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Guide for detecting areas and text in an image</h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important things for the protocol:\n",
    "\n",
    "1. Circles in the paper have to be really separate. It will be easy split both circles.\n",
    "2. Unncessary letters and lines for the processing have to be in light color. It will help in umbralization process. \n",
    "3. It is important to use thick marks for relevant lines\n",
    "4. Stickers can't cut the lines because after it will not be possible separete this section\n",
    "5. Script works better with uppercase letters while they are aligned (we tryed with numbers and lowercase letter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src= \"sources/processing_detect_text.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x23ebc28ef98>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Open image \n",
    "path = r'scanner/'\n",
    "pathSave = r'./areas/'\n",
    "pathNumbers = r'./numbers/'\n",
    "pathTexts = r'./texts/'\n",
    "imageName = '29.jpg'\n",
    "image = cv2.imread(path + imageName) \n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x23e8f920390>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split images in the same page\n",
    "\n",
    "middle = int(len(image)/2) \n",
    "\n",
    "image1 = image[:middle]\n",
    "plt.imshow(image1)\n",
    "\n",
    "image2 = image[middle:]\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(image2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x23ebc22dd30>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select image (image1 or image 2) for processing and binarization \n",
    "\n",
    "setImage = image1\n",
    "threshold = 170\n",
    "\n",
    "grayImage = cv2.cvtColor(setImage, cv2.COLOR_BGR2GRAY)\n",
    "_, binaryImage = cv2.threshold(grayImage, threshold, 255, cv2.THRESH_BINARY)\n",
    "plt.imshow(binaryImage)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x23ebc27f358>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Binarization to get numbers\n",
    "\n",
    "threshold = 45\n",
    "_, number = cv2.threshold(grayImage, threshold, 255, cv2.THRESH_BINARY)\n",
    "kernel = np.ones((3, 3), np.uint8)\n",
    "number = cv2.dilate(~number, kernel, iterations=4)\n",
    "\n",
    "plt.imshow(number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x23e93e710f0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete number in the image \n",
    "\n",
    "result = ~binaryImage - (number)\n",
    "plt.imshow(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x23e8f9263c8>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get exteral contour and separate main circle \n",
    "\n",
    "r,c = np.shape(grayImage)\n",
    "ext = np.zeros((r,c), np.dtype('uint8'))\n",
    "    \n",
    "contour,_ = cv2.findContours(result, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "ext = cv2.drawContours(ext, contour, -1, 255, -1)\n",
    "plt.imshow(ext)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x23e93e71c50>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mask with external contour \n",
    "\n",
    "imaIn = ~result*ext\n",
    "kernel = np.ones((3, 3), np.uint8)\n",
    "splitArea = cv2.dilate(~imaIn, kernel, iterations=3)\n",
    "plt.imshow(splitArea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sections: 78\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x23ebc271080>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify secction and put specific lables for each one\n",
    "\n",
    "sections, labels = cv2.connectedComponents(imaIn)\n",
    "print('Number of sections: ' + str(sections-1))\n",
    "plt.imshow(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area  13691528\n",
      "Area  582623\n",
      "Area  1852138\n",
      "Area  156423\n",
      "Area  227281\n",
      "Area  162416\n",
      "Area  177788\n",
      "Area  357215\n",
      "Area  186861\n",
      "Images saved in folder\n"
     ]
    }
   ],
   "source": [
    "# Get each section, make a mask with original image and save it\n",
    "for i in range(sections):\n",
    "    area = np.sum(labels==i)\n",
    "    if (area > 200):\n",
    "        print ('Area ', str(area))\n",
    "        section =  labels.copy()\n",
    "        section[section != i] = 0\n",
    "        section[section == i] = 255\n",
    "        newSection = section.astype(np.uint8)\n",
    "        newImage = cv2.bitwise_and(setImage, setImage, mask=newSection)\n",
    "        cv2.imwrite( pathSave + str(area) +'.png', newImage)\n",
    "\n",
    "print('Images saved in folder')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 align=\"center\">Secction for text processing - One image</h3> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part is posible to load an image and get the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x23e93d6bcc0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load letter image  \n",
    "imageName = '357215.png'\n",
    "image = cv2.imread(pathSave + imageName) \n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sections: 23\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x23e93d83908>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate section\n",
    "\n",
    "threshold = 200\n",
    "grayImage = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "_, binaryImage = cv2.threshold(grayImage, threshold, 255, cv2.THRESH_BINARY)\n",
    "kernel = np.ones((2, 2), np.uint8)\n",
    "splitArea = cv2.dilate(~binaryImage, kernel, iterations=2)\n",
    "plt.imshow(splitArea)\n",
    "\n",
    "sections, labels = cv2.connectedComponents(splitArea)\n",
    "print('Number of sections: ' + str(sections-1))\n",
    "plt.imshow(labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area  8480\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x23e93d49f28>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get only the number\n",
    "\n",
    "for i in range(sections):\n",
    "    area = np.sum(labels==i)\n",
    "    \n",
    "    if (area > 200 and area < 10000):\n",
    "        print ('Area ', str(area))\n",
    "        section =  labels.copy()\n",
    "        section[section != i] = 0\n",
    "        section[section == i] = 255\n",
    "        number = section.astype(np.uint8)\n",
    "        cv2.imwrite( pathNumbers + imageName[:-4] + '.png', ~number)\n",
    "\n",
    "plt.imshow(binaryImage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area E\n",
      "\f",
      "tiene 357215\n"
     ]
    }
   ],
   "source": [
    "# Use tesseract library for getting text \n",
    "\n",
    "import os\n",
    "commandLine = 'tesseract ' + pathNumbers + imageName[:-4] + '.png' + ' ' + pathTexts + imageName[:-4] + ' -l eng --psm 6'\n",
    "os.system(commandLine)\n",
    "f = open(pathTexts + imageName[:-4] + '.txt', \"r\")\n",
    "text = f.read()\n",
    "print('Area ' + text + 'tiene ' + imageName[:-4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 align=\"center\">Secction for text processing - One folder with images</h3> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part is posible to detect the text in a group of image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['118411.png', '13672478.png', '2272593.png', '239763.png', '248540.png', '301128.png', '541542.png']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "files = os.listdir(pathSave)\n",
    "print (files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: 118411.png\n",
      "Area: 4\n",
      "\f",
      "Pixeles: 118411\n",
      "\n",
      "Processing: 13672478.png\n",
      "Processing: 2272593.png\n",
      "Processing: 239763.png\n",
      "Area: 1\n",
      "\f",
      "Pixeles: 239763\n",
      "\n",
      "Processing: 248540.png\n",
      "Area: 2\n",
      "\f",
      "Pixeles: 248540\n",
      "\n",
      "Processing: 301128.png\n",
      "Area: 3\n",
      "\f",
      "Pixeles: 301128\n",
      "\n",
      "Processing: 541542.png\n",
      "Area: o\n",
      "\f",
      "Pixeles: 541542\n",
      "\n",
      "Area: â€”â€”\n",
      "\f",
      "Pixeles: 541542\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for imageName in files:\n",
    "    print ('Processing: ' + imageName)\n",
    "    if int(imageName[:-4]) < 13000000:\n",
    "        image = cv2.imread(pathSave + imageName) \n",
    "        threshold = 200\n",
    "        grayImage = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        _, binaryImage = cv2.threshold(grayImage, threshold, 255, cv2.THRESH_BINARY)\n",
    "        kernel = np.ones((2, 2), np.uint8)\n",
    "        splitArea = cv2.dilate(~binaryImage, kernel, iterations=2)\n",
    "        sections, labels = cv2.connectedComponents(splitArea)\n",
    "        for i in range(sections):\n",
    "            area = np.sum(labels==i)\n",
    "            if (area > 400 and area < 10000):\n",
    "                section =  labels.copy()\n",
    "                section[section != i] = 0\n",
    "                section[section == i] = 255\n",
    "                number = section.astype(np.uint8)\n",
    "                kernel = np.ones((2, 2), np.uint8)\n",
    "                numberErode= cv2.erode(number, kernel, iterations=1)\n",
    "                cv2.imwrite( pathNumbers + imageName[:-4] + '.png', ~numberErode)\n",
    "                #cv2.imwrite( pathNumbers + imageName[:-4] + '.png', ~number)\n",
    "                commandLine = 'tesseract ' + pathNumbers + imageName[:-4] + '.png' + ' ' + pathTexts + imageName[:-4] + ' -l eng --psm 6'\n",
    "                os.system(commandLine)\n",
    "                f = open(pathTexts + imageName[:-4] + '.txt', \"r\")\n",
    "                text = f.read()\n",
    "                print('Area: ' + text + 'Pixeles: ' + imageName[:-4] +'\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Useful information for tesserat commands:\n",
    "\n",
    "tesseract --help-psm\n",
    "Page segmentation modes:\n",
    "  0    Orientation and script detection (OSD) only.\n",
    "  1    Automatic page segmentation with OSD.\n",
    "  2    Automatic page segmentation, but no OSD, or OCR.\n",
    "  3    Fully automatic page segmentation, but no OSD. (Default)\n",
    "  4    Assume a single column of text of variable sizes.\n",
    "  5    Assume a single uniform block of vertically aligned text.\n",
    "  6    Assume a single uniform block of text.\n",
    "  7    Treat the image as a single text line.\n",
    "  8    Treat the image as a single word.\n",
    "  9    Treat the image as a single word in a circle.\n",
    " 10    Treat the image as a single character.\n",
    " 11    Sparse text. Find as much text as possible in no particular order.\n",
    " 12    Sparse text with OSD.\n",
    " 13    Raw line. Treat the image as a single text line,\n",
    "       bypassing hacks that are Tesseract-specific.\n",
    " \n",
    " tesseract numero2.png outputbase -l eng --psm 6"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
